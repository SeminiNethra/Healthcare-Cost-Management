{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOMofGrm0AAm1nsVIwYshNE",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SeminiNethra/Healthcare-Cost-Management/blob/main/Model_Expalinability.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qXiRrWsOQWu6",
        "outputId": "bd0ad761-d86d-4f3b-a21b-51c4113dd2ac"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unique values in target before mapping: ['Under 10, 000 ' '50, 000 - 100, 000' '10, 000 - 50,000' 'Under 10, 019'\n",
            " 'Under 10, 020']\n",
            "Unique values in target after mapping: [ 5000. 75000. 30000.    nan]\n",
            "Shape after dropping missing target: (96, 17)\n",
            "Categorical columns used: ['Sex', 'City You Live In', 'Monthly Income Level', 'Do You Have Any Chronic Disease', 'Do you have any allergies?', 'Do you consume alcoholic beverages?', 'Do you smoke or use tobacco products?', 'what type of hospital do you typically spend on medication per month?']\n",
            "Shape after encoding: (96, 42)\n",
            "Final DataFrame shape before split: (96, 37)\n",
            "Shape of x before split: (96, 36)\n",
            "Shape of y before split: (96,)\n",
            "Train/test split shapes: (72, 36) (24, 36) (72,) (24,)\n",
            "\n",
            "========================================\n",
            "Training Random Forest\n",
            "========================================\n",
            "Fitting 3 folds for each of 24 candidates, totalling 72 fits\n",
            "Best parameters: {'max_depth': 10, 'max_features': 'log2', 'min_samples_split': 5, 'n_estimators': 100}\n",
            "\n",
            "========================================\n",
            "Training XGBoost\n",
            "========================================\n",
            "Fitting 3 folds for each of 32 candidates, totalling 96 fits\n",
            "Best parameters: {'colsample_bytree': 1.0, 'learning_rate': 0.01, 'max_depth': 6, 'n_estimators': 200, 'subsample': 0.8}\n",
            "\n",
            "========================================\n",
            "Training Gradient Boosting\n",
            "========================================\n",
            "Fitting 3 folds for each of 8 candidates, totalling 24 fits\n",
            "Best parameters: {'learning_rate': 0.01, 'max_depth': 5, 'n_estimators': 100}\n",
            "\n",
            "========================================\n",
            "Training Linear Regression\n",
            "========================================\n",
            "\n",
            "Model Comparison Report:\n",
            "            Model       R2          MAE         RMSE                                                                                             Best Params\n",
            "          XGBoost 0.358369  7630.358846 16199.292547 {'colsample_bytree': 1.0, 'learning_rate': 0.01, 'max_depth': 6, 'n_estimators': 200, 'subsample': 0.8}\n",
            "    Random Forest 0.311262  9219.271462 16783.422305                  {'max_depth': 10, 'max_features': 'log2', 'min_samples_split': 5, 'n_estimators': 100}\n",
            "Gradient Boosting 0.263624  9336.161238 17354.143472                                            {'learning_rate': 0.01, 'max_depth': 5, 'n_estimators': 100}\n",
            "Linear Regression 0.171013 10627.626916 18413.116184                                                                                                     N/A\n"
          ]
        }
      ],
      "source": [
        "# model_training.py\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import joblib\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "import xgboost as xgb\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load and preprocess data\n",
        "df = pd.read_csv('/content/Final Year Project Dataset - Sheet1 (1).csv')\n",
        "\n",
        "# Clean and convert the target column to numeric\n",
        "target_col = 'What is the average halthcare bill amount?'\n",
        "\n",
        "def bill_to_num(x):\n",
        "    if pd.isna(x) or x == 'Nothing':\n",
        "        return np.nan\n",
        "    x = str(x).replace(',', '').replace(' ', '').lower()\n",
        "    if 'under10000' in x:\n",
        "        return 5000\n",
        "    elif '10000-50000' in x:\n",
        "        return 30000\n",
        "    elif '50000-100000' in x:\n",
        "        return 75000\n",
        "    elif 'morethan100000' in x:\n",
        "        return 150000\n",
        "    try:\n",
        "        return float(x)\n",
        "    except:\n",
        "        return np.nan\n",
        "\n",
        "print(\"Unique values in target before mapping:\", df[target_col].unique())\n",
        "df[target_col] = df[target_col].apply(bill_to_num)\n",
        "print(\"Unique values in target after mapping:\", df[target_col].unique())\n",
        "\n",
        "# Drop rows where target is missing\n",
        "df = df.dropna(subset=[target_col])\n",
        "print(\"Shape after dropping missing target:\", df.shape)\n",
        "\n",
        "# Define categorical columns (use only those that exist)\n",
        "cat_cols = [\n",
        "    'Sex',\n",
        "    'City You Live In',\n",
        "    'Monthly Income Level',\n",
        "    'Do You Have Any Chronic Disease',\n",
        "    'Do you have any allergies?',\n",
        "    'Do you consume alcoholic beverages?',\n",
        "    'Do you smoke or use tobacco products?',\n",
        "    'what type of hospital do you typically spend on medication per month?'\n",
        "]\n",
        "cat_cols = [col for col in cat_cols if col in df.columns]\n",
        "print(\"Categorical columns used:\", cat_cols)\n",
        "\n",
        "# Replace 'Nothing' with np.nan throughout the entire DataFrame\n",
        "df = df.replace('Nothing', np.nan)\n",
        "\n",
        "# Fill missing values in categorical columns\n",
        "for col in cat_cols:\n",
        "    df[col] = df[col].fillna('Missing')\n",
        "\n",
        "# One-hot encode categorical columns\n",
        "df = pd.get_dummies(df, columns=cat_cols, drop_first=True)\n",
        "print(\"Shape after encoding:\", df.shape)\n",
        "\n",
        "# Drop unnecessary columns if present\n",
        "drop_cols = [\n",
        "    'Name',\n",
        "    'If Yes, please specify',\n",
        "    'Have you undergone any prior surgeries or procedures?',\n",
        "    'If yes, please specify',\n",
        "    'Do you have any other medical history that we should be aware of?'\n",
        "]\n",
        "for col in drop_cols:\n",
        "    if col in df.columns:\n",
        "        df = df.drop(col, axis=1)\n",
        "\n",
        "# Convert all remaining string columns to numeric\n",
        "for col in df.columns:\n",
        "    if df[col].dtype == object:\n",
        "        df[col] = pd.to_numeric(df[col], errors='coerce')\n",
        "\n",
        "# Fill any remaining missing values with 0\n",
        "df = df.fillna(0)\n",
        "\n",
        "# Check if df is empty before proceeding\n",
        "print(\"Final DataFrame shape before split:\", df.shape)\n",
        "if df.shape[0] == 0:\n",
        "    raise ValueError(\"No data left after cleaning! Check the cleaning steps and your raw data.\")\n",
        "\n",
        "# Prepare features and target\n",
        "x = df.drop([target_col], axis=1)\n",
        "y = df[target_col]\n",
        "\n",
        "print(\"Shape of x before split:\", x.shape)\n",
        "print(\"Shape of y before split:\", y.shape)\n",
        "\n",
        "# Now split\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.25, random_state=42)\n",
        "print(\"Train/test split shapes:\", x_train.shape, x_test.shape, y_train.shape, y_test.shape)\n",
        "\n",
        "\n",
        "# Save feature names after preprocessing\n",
        "joblib.dump(list(x.columns), 'train_features.pkl')\n",
        "\n",
        "# Model comparison with hyperparameter tuning\n",
        "models = {\n",
        "    'Random Forest': {\n",
        "        'model': RandomForestRegressor(random_state=42),\n",
        "        'params': {\n",
        "            'n_estimators': [100, 200],\n",
        "            'max_depth': [None, 10, 20],\n",
        "            'min_samples_split': [2, 5],\n",
        "            'max_features': ['sqrt', 'log2']\n",
        "        }\n",
        "    },\n",
        "    'XGBoost': {\n",
        "        'model': xgb.XGBRegressor(random_state=42),\n",
        "        'params': {\n",
        "            'n_estimators': [100, 200],\n",
        "            'learning_rate': [0.01, 0.1],\n",
        "            'max_depth': [3, 6],\n",
        "            'subsample': [0.8, 1.0],\n",
        "            'colsample_bytree': [0.8, 1.0]\n",
        "        }\n",
        "    },\n",
        "    'Gradient Boosting': {\n",
        "        'model': GradientBoostingRegressor(random_state=42),\n",
        "        'params': {\n",
        "            'n_estimators': [100, 200],\n",
        "            'learning_rate': [0.01, 0.1],\n",
        "            'max_depth': [3, 5]\n",
        "        }\n",
        "    },\n",
        "    'Linear Regression': {\n",
        "        'model': LinearRegression(),\n",
        "        'params': {}\n",
        "    }\n",
        "}\n",
        "\n",
        "results = []\n",
        "\n",
        "for name, config in models.items():\n",
        "    print(f\"\\n{'='*40}\\nTraining {name}\\n{'='*40}\")\n",
        "\n",
        "    # Hyperparameter tuning\n",
        "    if config['params']:\n",
        "        gs = GridSearchCV(config['model'], config['params'],\n",
        "                         cv=3, scoring='r2', n_jobs=-1, verbose=1)\n",
        "        gs.fit(x_train, y_train)\n",
        "        best_model = gs.best_estimator_\n",
        "        print(f\"Best parameters: {gs.best_params_}\")\n",
        "    else:\n",
        "        best_model = config['model'].fit(x_train, y_train)\n",
        "\n",
        "    # Evaluation\n",
        "    y_pred = best_model.predict(x_test)\n",
        "    metrics = {\n",
        "        'Model': name,\n",
        "        'R2': r2_score(y_test, y_pred),\n",
        "        'MAE': mean_absolute_error(y_test, y_pred),\n",
        "        'RMSE': np.sqrt(mean_squared_error(y_test, y_pred)),\n",
        "        'Best Params': str(gs.best_params_) if config['params'] else 'N/A'\n",
        "    }\n",
        "    results.append(metrics)\n",
        "\n",
        "    # Save model and tuning results\n",
        "    joblib.dump(best_model, f'model_{name.lower().replace(\" \", \"_\")}.pkl')\n",
        "    joblib.dump(gs.cv_results_, f'{name.lower()}_cv_results.pkl')\n",
        "\n",
        "# Create comparison report\n",
        "results_df = pd.DataFrame(results)\n",
        "results_df = results_df.sort_values('R2', ascending=False)\n",
        "print(\"\\nModel Comparison Report:\")\n",
        "print(results_df.to_string(index=False))\n",
        "\n",
        "# Save comparison plot\n",
        "plt.figure(figsize=(10, 6))\n",
        "results_df.set_index('Model')['R2'].plot(kind='barh')\n",
        "plt.title('Model Comparison (RÂ² Score)')\n",
        "plt.tight_layout()\n",
        "plt.savefig('model_comparison.png')\n",
        "plt.close()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#app.py\n",
        "%%writefile app.py\n",
        "import streamlit as st\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import joblib\n",
        "import shap\n",
        "\n",
        "st.title('Healthcare Cost Prediction')\n",
        "st.write(\"Enter patient details to predict estimated healthcare cost.\")\n",
        "\n",
        "# Load the trained model and feature names\n",
        "try:\n",
        "    train_features = joblib.load('train_features.pkl')\n",
        "\n",
        "    # Try to load multiple models with error handling\n",
        "    models = {}\n",
        "    available_models = ['Random Forest', 'XGBoost', 'Gradient Boosting', 'Linear Regression']\n",
        "    for model_name in available_models:\n",
        "        try:\n",
        "            model_filename = f\"model_{model_name.lower().replace(' ', '_')}.pkl\"\n",
        "            models[model_name] = joblib.load(model_filename)\n",
        "        except FileNotFoundError:\n",
        "            pass\n",
        "\n",
        "    if not models:\n",
        "        st.error(\"No model files found. Please ensure models are trained and available.\")\n",
        "        st.stop()\n",
        "\n",
        "    # Set default selected model\n",
        "    selected_model = list(models.keys())[0]\n",
        "\n",
        "    # Try to load model comparison results\n",
        "    try:\n",
        "        results_df = pd.read_csv('model_comparison.csv')\n",
        "        st.subheader(\"Performance Comparison\")\n",
        "        col1, col2 = st.columns(2)\n",
        "        with col2:\n",
        "            st.dataframe(results_df.style.format({'R2': '{:.3f}', 'MAE': '{:.1f}', 'RMSE': '{:.1f}'}))\n",
        "        with col1:\n",
        "            try:\n",
        "                st.image('model_comparison.png')\n",
        "            except:\n",
        "                plt.figure(figsize=(10, 6))\n",
        "                plt.bar(results_df['Model'], results_df['R2'])\n",
        "                plt.title('Model Comparison (RÂ² Score)')\n",
        "                plt.ylim(0, 1)\n",
        "                st.pyplot(plt)\n",
        "    except FileNotFoundError:\n",
        "        st.warning(\"Model comparison data not available\")\n",
        "\n",
        "    # Hyperparameter details\n",
        "    if len(models) > 1:\n",
        "        st.subheader(\"Best Hyperparameters\")\n",
        "        selected_model = st.selectbox(\"Select model to view parameters\", list(models.keys()))\n",
        "    model = models[selected_model]\n",
        "    try:\n",
        "        params = model.get_params()\n",
        "        st.json(params)\n",
        "    except AttributeError:\n",
        "        st.warning(\"Hyperparameters not available for this model\")\n",
        "\n",
        "    # Feature importance visualization\n",
        "    st.subheader(\"Feature Importance\")\n",
        "    if hasattr(model, 'feature_importances_'):\n",
        "        importances = model.feature_importances_\n",
        "        fi_df = pd.DataFrame({'Feature': train_features, 'Importance': importances})\n",
        "        fi_df = fi_df.nlargest(10, 'Importance').sort_values('Importance', ascending=True)\n",
        "        plt.figure(figsize=(10, 6))\n",
        "        plt.barh(fi_df['Feature'], fi_df['Importance'])\n",
        "        plt.title('Top 10 Important Features')\n",
        "        st.pyplot(plt)\n",
        "    else:\n",
        "        st.warning(\"Feature importance not available for this model type\")\n",
        "\n",
        "    # Prediction interface\n",
        "    st.header(\"Cost Prediction Interface\")\n",
        "    # User input\n",
        "    age = st.slider(\"Age\", 0, 100, 30)\n",
        "    gender = st.selectbox(\"Gender\", [\"Male\", \"Female\"])\n",
        "    bmi = st.slider(\"BMI\", 10.0, 50.0, 22.0)\n",
        "    city = st.selectbox(\"City You Live In\", [\n",
        "        \"Biyagama\", \"Dehiwala\", \"Kalmunai\", \"Vavuniya\", \"Galle\", \"Trincomalee\",\n",
        "        \"Batticalo\", \"Jaffna\", \"Matale\", \"Katunayaka\", \"Dambulla\", \"Kolonnawa\",\n",
        "        \"Anuradhapura\", \"Rathnapura\", \"Moratuwa\", \"Sri Jayawardanapura Kotte\",\n",
        "        \"Chilaw\", \"Colombo\", \"Homagama\", \"Kandy\", \"Negombo\", \"Other\"\n",
        "    ])\n",
        "    income = st.selectbox(\"Monthly Income Level\", [\n",
        "        \"Less than 25,000\", \"25,000-50,000\", \"50,000-100,000\",\n",
        "        \"More than 100,000\"])\n",
        "    chronic_disease = st.selectbox(\"Do You Have Any Chronic Disease\", [\"Yes\", \"No\"])\n",
        "    allergies = st.selectbox(\"Do you have any allergies?\", [\"Yes\", \"No\"])\n",
        "    alcohol = st.selectbox(\"Do you consume alcoholic beverages?\", [\"Yes\", \"No\"])\n",
        "    tobacco = st.selectbox(\"Do you smoke or use tobacco products?\", [\"Yes\", \"No\"])\n",
        "    hospital_type = st.selectbox(\"What type of hospital do you typically spend on medication per month?\",\n",
        "                              [\"Government\", \"Private\", \"Both\"])\n",
        "\n",
        "    # Initialize a dictionary with zeros for all expected columns\n",
        "    input_dict = {col: 0 for col in train_features}\n",
        "    # Set numerical features\n",
        "    if \"Age\" in train_features: input_dict[\"Age\"] = age\n",
        "    if \"BMI\" in train_features: input_dict[\"BMI\"] = bmi\n",
        "    # Set one-hot encoded categorical variables\n",
        "    if (col := f\"Sex_{gender}\") in train_features: input_dict[col] = 1\n",
        "    if (col := f\"City You Live In_{city}\") in train_features: input_dict[col] = 1\n",
        "    if (col := f\"Monthly Income Level_{income}\") in train_features: input_dict[col] = 1\n",
        "    if (col := f\"Do You Have Any Chronic Disease_{chronic_disease}\") in train_features: input_dict[col] = 1\n",
        "    if (col := f\"Do you have any allergies?_{allergies}\") in train_features: input_dict[col] = 1\n",
        "    if (col := f\"Do you consume alcoholic beverages?_{alcohol}\") in train_features: input_dict[col] = 1\n",
        "    if (col := f\"Do you smoke or use tobacco products?_{tobacco}\") in train_features: input_dict[col] = 1\n",
        "    if (col := f\"what type of hospital do you typically spend on medication per month?_{hospital_type}\") in train_features: input_dict[col] = 1\n",
        "\n",
        "    input_df = pd.DataFrame([input_dict])[train_features]\n",
        "\n",
        "    if st.button(\"Predict\"):\n",
        "        try:\n",
        "            prediction = model.predict(input_df)[0]\n",
        "            st.success(f\"ğŸ’° Estimated Healthcare Cost: LKR {int(prediction):,}\")\n",
        "            st.subheader(\"Model Explainability (SHAP)\")\n",
        "            try:\n",
        "                # Use TreeExplainer for tree-based models\n",
        "                explainer = shap.TreeExplainer(model)\n",
        "                shap_values = explainer.shap_values(input_df)\n",
        "                # Global explanation\n",
        "                st.write(\"**Global Feature Impact:**\")\n",
        "                shap.summary_plot(shap_values, input_df, plot_type=\"bar\", show=False)\n",
        "                st.pyplot(plt.gcf())\n",
        "                plt.clf()\n",
        "                # Local explanation (for this prediction)\n",
        "                st.write(\"**This Prediction's Explanation:**\")\n",
        "                shap.initjs()\n",
        "                force_plot = shap.force_plot(explainer.expected_value, shap_values[0], input_df.iloc[0], matplotlib=True, show=False)\n",
        "                st.pyplot(force_plot.figure)\n",
        "            except Exception as e:\n",
        "                st.warning(f\"SHAP explanation not available: {e}\")\n",
        "        except Exception as e:\n",
        "            st.error(f\"Prediction error: {str(e)}\")\n",
        "            st.info(\"Please check that all feature names match exactly with training data.\")\n",
        "\n",
        "except FileNotFoundError as e:\n",
        "    st.error(f\"Required file not found: {str(e)}\")\n",
        "    st.info(\"Please make sure you've run the model training code that creates train_features.pkl and model files.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GfAt4cnxl7hC",
        "outputId": "370710f3-49d5-4b78-b079-3186597c7d77"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing app.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q streamlit\n",
        "!npm install -g localtunnel"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pxDcZdqRqlNJ",
        "outputId": "5f88e0eb-cb58-47d5-99bd-d6ab8821a76e"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m44.3/44.3 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m9.9/9.9 MB\u001b[0m \u001b[31m58.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m91.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m79.1/79.1 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[1G\u001b[0Kâ ™\u001b[1G\u001b[0Kâ ¹\u001b[1G\u001b[0Kâ ¸\u001b[1G\u001b[0Kâ ¼\u001b[1G\u001b[0Kâ ´\u001b[1G\u001b[0Kâ ¦\u001b[1G\u001b[0Kâ §\u001b[1G\u001b[0Kâ ‡\u001b[1G\u001b[0Kâ \u001b[1G\u001b[0Kâ ‹\u001b[1G\u001b[0Kâ ™\u001b[1G\u001b[0Kâ ¹\u001b[1G\u001b[0Kâ ¸\u001b[1G\u001b[0Kâ ¼\u001b[1G\u001b[0Kâ ´\u001b[1G\u001b[0Kâ ¦\u001b[1G\u001b[0Kâ §\u001b[1G\u001b[0Kâ ‡\u001b[1G\u001b[0Kâ \u001b[1G\u001b[0Kâ ‹\u001b[1G\u001b[0K\n",
            "added 22 packages in 2s\n",
            "\u001b[1G\u001b[0Kâ ‹\u001b[1G\u001b[0K\n",
            "\u001b[1G\u001b[0Kâ ‹\u001b[1G\u001b[0K3 packages are looking for funding\n",
            "\u001b[1G\u001b[0Kâ ‹\u001b[1G\u001b[0K  run `npm fund` for details\n",
            "\u001b[1G\u001b[0Kâ ‹\u001b[1G\u001b[0K"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -q -o - ipv4.icanhazip.com"
      ],
      "metadata": {
        "id": "nzH1SsW0quNY"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!streamlit run app.py & npx localtunnel --port 8501"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uGOVBd_9qzMo",
        "outputId": "4d6ae820-1a14-49bb-bd10-9bfe3f69630c"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1G\u001b[0Kâ ™\u001b[1G\u001b[0Kâ ¹\u001b[1G\u001b[0Kâ ¸\u001b[1G\u001b[0Kâ ¼\u001b[1G\u001b[0Kâ ´\u001b[1G\u001b[0Kâ ¦\u001b[1G\u001b[0Kâ §\u001b[1G\u001b[0Kâ ‡\n",
            "Collecting usage statistics. To deactivate, set browser.gatherUsageStats to false.\n",
            "\u001b[0m\n",
            "\u001b[1G\u001b[0Kâ \u001b[1G\u001b[0Kyour url is: https://shiny-showers-fly.loca.lt\n",
            "\u001b[0m\n",
            "\u001b[34m\u001b[1m  You can now view your Streamlit app in your browser.\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m  Local URL: \u001b[0m\u001b[1mhttp://localhost:8501\u001b[0m\n",
            "\u001b[34m  Network URL: \u001b[0m\u001b[1mhttp://172.28.0.12:8501\u001b[0m\n",
            "\u001b[34m  External URL: \u001b[0m\u001b[1mhttp://34.106.161.213:8501\u001b[0m\n",
            "\u001b[0m\n"
          ]
        }
      ]
    }
  ]
}